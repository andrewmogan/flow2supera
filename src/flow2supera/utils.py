import sys, os
import h5py
import h5flow
import numpy as np
import time
import flow2supera
import argparse
import ROOT
from edep2supera.utils import get_iomanager, larcv_meta, larcv_particle
#from LarpixParser import event_parser as EventParser
from larcv import larcv

def get_flow2supera(config_key):

    driver = flow2supera.driver.SuperaDriver()
    if os.path.isfile(config_key):
        driver.ConfigureFromFile(config_key)
    else:
        driver.ConfigureFromFile(flow2supera.config.get_config(config_key))
    
    return driver 

def log_supera_integrity_check(data, driver, log, verbose=False):

    if not log:
        return

    label = driver.Label()
    meta  = driver.Meta()

    # Packet tensor
    pcloud = np.array([[edep.x,edep.y,edep.z,edep.e] for edep in driver._edeps_all])
    voxels = meta.edep2voxelset(driver._edeps_all)
    voxels = np.array([[meta.pos_x(vox.id()),
                        meta.pos_y(vox.id()),
                        meta.pos_z(vox.id()),
                        vox.value()] for vox in voxels.as_vector()
                      ]
                     ) 
    
    cluster_sum = np.sum([p.energy.sum() for p in label.Particles()])
    input_sum  = np.sum([np.sum([edep.e for edep in p.pcloud]) for p in data])
    input_unass= np.sum([edep.e for edep in data.unassociated_edeps])
    energy_sum = label._energies.sum()
    energy_num = label._energies.size()
    pcloud_sum = np.sum(pcloud[:,3])
    pcloud_num = pcloud.shape[0]
    voxels_sum = np.sum(voxels[:,3])
    voxels_num = voxels.shape[0]
    unass_sum  = np.sum([vox.value() for vox in label._unassociated_voxels.as_vector()])
    
    if verbose:
        print('  Raw image    :',voxels_num,'voxels with the sum',voxels_sum)
        print('  Packets      :',pcloud_num,'packets with the sum',pcloud_sum)
        print('  Input cluster:',input_sum)
        print('  Input unass. :',input_unass)
        print('  Label image  :',energy_num,'voxels with the sum',energy_sum)
        print('  Label cluster:',cluster_sum)
        print('  Unassociated :',unass_sum)
        print('  Label image - (Cluster sum + Unassociated)',energy_sum - (cluster_sum + unass_sum))
        print('  Label image - Raw image',energy_sum - voxels_sum)
        print('  Packets - Raw image',pcloud_sum - voxels_sum)

    log['raw_image_sum'].append(voxels_sum)
    log['raw_image_npx'].append(voxels_num)
    log['raw_packet_sum'].append(pcloud_sum)
    log['raw_packet_num'].append(pcloud_num)
    log['in_cluster_sum'].append(input_sum)
    log['in_unass_sum'].append(input_unass)
    log['out_image_sum'].append(energy_sum)
    log['out_image_num'].append(energy_num)
    log['out_cluster_sum'].append(cluster_sum)
    log['out_unass_sum'].append(unass_sum)
    
# def larcv_flash(f):
        
#     larf=larcv.Flash()
    
#     larf.id              (int(f.id))
#     larf.time            (f.time)
#     larf.timeWidth       (f.timeWidth)
#     larf.PEPerOpDet      (f.PEPerOpDet)
#     # 
#     return larf

# Fill SuperaAtomic class and hand off to label-making
def run_supera(out_file='larcv.root',
               in_file='',
               config_key='',
               num_events=-1,
               num_flash_events=-1,
               num_skip=0,
               num_flash_skip=0,
               ignore_bad_association=True,
               save_log=None):

    start_time = time.time()

    writer = get_iomanager(out_file)
    driver = get_flow2supera(config_key)
    reader = flow2supera.reader.FlowReader(driver.parser_run_config(), in_file)
    #reader_flash = flow2supera.reader.FlowFlashReader(driver.parser_run_config(), in_file)

    id_vv = ROOT.std.vector("std::vector<unsigned long>")()
    value_vv = ROOT.std.vector("std::vector<float>")()

    id_v=ROOT.std.vector("unsigned long")()
    value_v=ROOT.std.vector("float")()

    if num_events < 0:
        num_events = len(reader)
    # if num_flash_events < 0:
    #     num_flash_events = len(reader_flash)

    print("--- startup {:.2e} seconds ---".format(time.time() - start_time))

    LOG_KEYS  = ['event_id','time_read','time_convert','time_generate', 'time_store', 'time_event']
    LOG_KEYS += ['raw_image_sum','raw_image_npx','raw_packet_sum','raw_packet_num',
    'in_cluster_sum','in_unass_sum','out_image_sum','out_image_num',
    'out_cluster_sum','out_unass_sum']

    logger = dict()
    if save_log:
        for key in LOG_KEYS:
            logger[key]=[]
        driver.log(logger)
        
    print("----------------Processing charge events----------------")
    for entry in range(len(reader)):

        if num_skip and entry < num_skip:
            continue

        if num_events <= 0:
            break

        num_events -= 1 

        print(f'Processing Entry {entry}')

        t0 = time.time()
        input_data = reader.GetEvent(entry)
        reader.EventDump(input_data)
        #is_good_event = reader.CheckIntegrity(input_data, ignore_bad_association)
        #if not is_good_event:
        #    print('[ERROR] Entry', entry, 'is not valid; skipping')
        #    continue
        time_read = time.time() - t0
        
        t1 = time.time()
        EventInput = driver.ReadEvent(input_data)
        time_convert = time.time() - t1

        t2 = time.time()
        driver.GenerateImageMeta(EventInput)
        driver.GenerateLabel(EventInput) 
        time_generate = time.time() - t2

        # Perform an integrity check
        if save_log:
            log_supera_integrity_check(EventInput, driver, logger, verbose)

        # Start data store process
        t3 = time.time()
        result = driver.Label()
        meta   = larcv_meta(driver.Meta())
        
        tensor_energy = writer.get_data("sparse3d", "pcluster")
        result.FillTensorEnergy(id_v, value_v)
        larcv.as_event_sparse3d(tensor_energy, meta, id_v, value_v)
        
        tensor_packets = writer.get_data("sparse3d", "packets")
        driver.Meta().edep2voxelset(driver._edeps_all).fill_std_vectors(id_v, value_v)
        larcv.as_event_sparse3d(tensor_packets, meta, id_v, value_v)

        tensor_semantic = writer.get_data("sparse3d", "pcluster_semantics")
        result.FillTensorSemantic(id_v, value_v)
        larcv.as_event_sparse3d(tensor_semantic,meta, id_v, value_v)

        cluster_energy = writer.get_data("cluster3d", "pcluster")
        result.FillClustersEnergy(id_vv, value_vv)
        larcv.as_event_cluster3d(cluster_energy, meta, id_vv, value_vv)

        cluster_dedx = writer.get_data("cluster3d", "pcluster_dedx")
        result.FillClustersdEdX(id_vv, value_vv)
        larcv.as_event_cluster3d(cluster_dedx, meta, id_vv, value_vv)

        particle = writer.get_data("particle", "pcluster")
        print("len particles", len(result._particles))
        for p in result._particles:
            if not p.valid:
                continue
            larp = larcv_particle(p)
            particle.append(larp)
            
        #propagating trigger info
        trigger = writer.get_data("trigger", "base")
        trigger.id(int(input_data.event_id))  # fixme: this will need to be different for real data?
        trigger.time_s(int(input_data.t0))
        trigger.time_ns(int(1e9 * (input_data.t0 - trigger.time_s())))
        
        # TODO fill the run ID 
        writer.set_id(0, 0, int(input_data.event_id))
        writer.save_entry()
        time_store = time.time() - t3

        time_event = time.time() - t0
        print("--- running driver  {:.2e} seconds ---".format(time_event))

        if save_log:
            logger['event_id'].append(input_data.event_id)
            logger['time_read'    ].append(time_read)
            logger['time_convert' ].append(time_convert)
            logger['time_generate'].append(time_generate)
            logger['time_store'   ].append(time_store)
            logger['time_event'   ].append(time_event)
        
#     print("----------------Processing light events----------------")
#     for entry in range(len(reader_flash)):
#         #FIXME: this loop also adds entry to other branches
#         if num_flash_skip and entry < num_flash_skip:
#             continue

#         if num_flash_events <= 0:
#             break

#         num_flash_events -= 1 

#         print(f'Processing Entry {entry}')

      
#         input_flash_data = reader_flash.GetFlash(entry)
#         reader_flash.FlashDump(input_flash_data)

#         flash_data = larcv_flash(input_flash_data)
#         flash = writer.get_data("opflash", "sipm_hits")
#         flash.append(flash_data) 
            
#         writer.set_id(0, 0, int(input_flash_data.id))
#         writer.save_entry()


    writer.finalize()

    if save_log:
        np.savez('log_flow2supera.npz',**logger)

    print("done")   








